{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa924e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7dd9f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer import SGD, AdaGrad, AdaDelta, Adam\n",
    "from torch.nn import Parameter\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05cb581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(x: torch.Tensor) -> torch.Tensor:\n",
    "    return (x-3) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7d52ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, x: 0.6000000238418579, loss: 9.0000\n",
      "Step: 2, x: 1.0800000429153442, loss: 5.7600\n",
      "Step: 3, x: 1.4639999866485596, loss: 3.6864\n",
      "Step: 4, x: 1.7711999416351318, loss: 2.3593\n",
      "Step: 5, x: 2.0169599056243896, loss: 1.5099\n",
      "Step: 6, x: 2.2135679721832275, loss: 0.9664\n",
      "Step: 7, x: 2.370854377746582, loss: 0.6185\n",
      "Step: 8, x: 2.4966835975646973, loss: 0.3958\n",
      "Step: 9, x: 2.597346782684326, loss: 0.2533\n",
      "Step: 10, x: 2.677877426147461, loss: 0.1621\n",
      "Step: 11, x: 2.7423019409179688, loss: 0.1038\n",
      "Step: 12, x: 2.793841600418091, loss: 0.0664\n",
      "Step: 13, x: 2.835073232650757, loss: 0.0425\n",
      "Step: 14, x: 2.868058681488037, loss: 0.0272\n",
      "Step: 15, x: 2.894446849822998, loss: 0.0174\n",
      "Step: 16, x: 2.915557384490967, loss: 0.0111\n",
      "Step: 17, x: 2.932446002960205, loss: 0.0071\n",
      "Step: 18, x: 2.9459567070007324, loss: 0.0046\n",
      "Step: 19, x: 2.9567654132843018, loss: 0.0029\n",
      "Step: 20, x: 2.9654123783111572, loss: 0.0019\n",
      "Step: 21, x: 2.97232985496521, loss: 0.0012\n",
      "difference in loss is less than the threshold; stopping\n"
     ]
    }
   ],
   "source": [
    "x = Parameter(data=torch.tensor([0.0]), requires_grad=True)\n",
    "optimizer = SGD(lr=0.1, params=[x], momentum=None)\n",
    "\n",
    "loss_threshold = 1e-3\n",
    "prev_loss = 0\n",
    "\n",
    "for step in range(50):\n",
    "    loss = loss_fn(x)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Step: {step+1}, x: {x.item()}, loss: {loss.item():.4f}\")\n",
    "\n",
    "    if abs(prev_loss - loss.item()) < loss_threshold:\n",
    "        print(f\"difference in loss is less than the threshold; stopping\")\n",
    "        break\n",
    "    prev_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fd512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, x: 0.6000000238418579, loss: 9.0000\n",
      "Step: 2, x: 1.380000114440918, loss: 5.7600\n",
      "Step: 3, x: 2.0940001010894775, loss: 2.6244\n",
      "Step: 4, x: 2.632200002670288, loss: 0.8208\n",
      "Step: 5, x: 2.9748599529266357, loss: 0.1353\n",
      "Step: 6, x: 3.1512179374694824, loss: 0.0006\n",
      "Step: 7, x: 3.209153413772583, loss: 0.0229\n",
      "Step: 8, x: 3.1962904930114746, loss: 0.0437\n",
      "Step: 9, x: 3.1506009101867676, loss: 0.0385\n",
      "Step: 10, x: 3.0976359844207764, loss: 0.0227\n",
      "Step: 11, x: 3.051626205444336, loss: 0.0095\n",
      "Step: 12, x: 3.018296241760254, loss: 0.0027\n",
      "Step: 13, x: 2.997972011566162, loss: 0.0003\n",
      "Step: 14, x: 2.988215446472168, loss: 0.0000\n",
      "difference in loss is less than the threshold; stopping\n"
     ]
    }
   ],
   "source": [
    "x = Parameter(data=torch.tensor([0.0]), requires_grad=True)\n",
    "optimizer = SGD(lr=0.1, params=[x], momentum=0.5)\n",
    "\n",
    "loss_threshold = 1e-3\n",
    "prev_loss = 0\n",
    "\n",
    "for step in range(50):\n",
    "    loss = loss_fn(x)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Step: {step+1}, x: {x.item()}, loss: {loss.item():.4f}\")\n",
    "\n",
    "    if abs(prev_loss - loss.item()) < loss_threshold:\n",
    "        print(f\"difference in loss is less than the threshold; stopping\")\n",
    "        break\n",
    "    prev_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6577e9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, x: 1.0, loss: 9.0000\n",
      "Step: 2, x: 1.5547001361846924, loss: 4.0000\n",
      "Step: 3, x: 1.926774024963379, loss: 2.0889\n",
      "Step: 4, x: 2.193084716796875, loss: 1.1518\n",
      "Step: 5, x: 2.389416217803955, loss: 0.6511\n",
      "Step: 6, x: 2.536365270614624, loss: 0.3728\n",
      "Step: 7, x: 2.6472599506378174, loss: 0.2150\n",
      "Step: 8, x: 2.7313315868377686, loss: 0.1244\n",
      "Step: 9, x: 2.7952346801757812, loss: 0.0722\n",
      "Step: 10, x: 2.8438806533813477, loss: 0.0419\n",
      "Step: 11, x: 2.8809444904327393, loss: 0.0244\n",
      "Step: 12, x: 2.9091978073120117, loss: 0.0142\n",
      "Step: 13, x: 2.930741310119629, loss: 0.0082\n",
      "Step: 14, x: 2.947171211242676, loss: 0.0048\n",
      "Step: 15, x: 2.959702491760254, loss: 0.0028\n",
      "Step: 16, x: 2.9692609310150146, loss: 0.0016\n",
      "Step: 17, x: 2.9765520095825195, loss: 0.0009\n",
      "difference in loss is less than the threshold; stopping\n"
     ]
    }
   ],
   "source": [
    "x = Parameter(data=torch.tensor([0.0]), requires_grad=True)\n",
    "optimizer = AdaGrad(lr=1, params=[x])\n",
    "\n",
    "loss_threshold = 1e-3\n",
    "prev_loss = 0\n",
    "\n",
    "for step in range(50):\n",
    "    loss = loss_fn(x)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Step: {step+1}, x: {x.item()}, loss: {loss.item():.4f}\")\n",
    "\n",
    "    if abs(prev_loss - loss.item()) < loss_threshold:\n",
    "        print(f\"difference in loss is less than the threshold; stopping\")\n",
    "        break\n",
    "    prev_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882ff380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, x: 3.163859946653247e-05, loss: 9.0000\n",
      "Step: 2, x: 7.635998190380633e-05, loss: 8.9998\n",
      "Step: 3, x: 0.00013112311717122793, loss: 8.9995\n",
      "Step: 4, x: 0.00019435286230873317, loss: 8.9992\n",
      "Step: 5, x: 0.00026504232664592564, loss: 8.9988\n",
      "Step: 6, x: 0.0003424761525820941, loss: 8.9984\n",
      "Step: 7, x: 0.00042611226672306657, loss: 8.9979\n",
      "Step: 8, x: 0.0005155213875696063, loss: 8.9974\n",
      "Step: 9, x: 0.0006103527848608792, loss: 8.9969\n",
      "Step: 10, x: 0.0007103127427399158, loss: 8.9963\n",
      "Step: 11, x: 0.0008151506772264838, loss: 8.9957\n",
      "Step: 12, x: 0.0009246495319530368, loss: 8.9951\n",
      "Step: 13, x: 0.001038618735037744, loss: 8.9945\n",
      "Step: 14, x: 0.0011568896006792784, loss: 8.9938\n",
      "Step: 15, x: 0.0012793110217899084, loss: 8.9931\n",
      "Step: 16, x: 0.0014057466760277748, loss: 8.9923\n",
      "Step: 17, x: 0.001536073163151741, loss: 8.9916\n",
      "Step: 18, x: 0.001670177560299635, loss: 8.9908\n",
      "Step: 19, x: 0.0018079562578350306, loss: 8.9900\n",
      "Step: 20, x: 0.0019493139116093516, loss: 8.9892\n",
      "Step: 21, x: 0.002094161929562688, loss: 8.9883\n",
      "Step: 22, x: 0.002242418471723795, loss: 8.9874\n",
      "Step: 23, x: 0.0023940065875649452, loss: 8.9866\n",
      "Step: 24, x: 0.002548854798078537, loss: 8.9856\n",
      "Step: 25, x: 0.0027068958152085543, loss: 8.9847\n",
      "Step: 26, x: 0.002868066541850567, loss: 8.9838\n",
      "Step: 27, x: 0.0030323071405291557, loss: 8.9828\n",
      "Step: 28, x: 0.0031995612662285566, loss: 8.9818\n",
      "Step: 29, x: 0.003369775600731373, loss: 8.9808\n",
      "Step: 30, x: 0.0035428996197879314, loss: 8.9798\n",
      "Step: 31, x: 0.0037188853602856398, loss: 8.9788\n",
      "Step: 32, x: 0.0038976867217570543, loss: 8.9777\n",
      "Step: 33, x: 0.0040792603977024555, loss: 8.9766\n",
      "Step: 34, x: 0.004263564478605986, loss: 8.9755\n",
      "Step: 35, x: 0.004450558684766293, loss: 8.9744\n",
      "Step: 36, x: 0.004640205297619104, loss: 8.9733\n",
      "Step: 37, x: 0.004832467995584011, loss: 8.9722\n",
      "Step: 38, x: 0.005027311388403177, loss: 8.9710\n",
      "Step: 39, x: 0.0052247014828026295, loss: 8.9699\n",
      "Step: 40, x: 0.0054246061481535435, loss: 8.9687\n",
      "Step: 41, x: 0.00562699418514967, loss: 8.9675\n",
      "Step: 42, x: 0.005831835325807333, loss: 8.9663\n",
      "Step: 43, x: 0.00603910069912672, loss: 8.9650\n",
      "Step: 44, x: 0.006248761899769306, loss: 8.9638\n",
      "Step: 45, x: 0.006460792385041714, loss: 8.9625\n",
      "Step: 46, x: 0.0066751656122505665, loss: 8.9613\n",
      "Step: 47, x: 0.00689185643568635, loss: 8.9600\n",
      "Step: 48, x: 0.0071108401753008366, loss: 8.9587\n",
      "Step: 49, x: 0.007332093082368374, loss: 8.9574\n",
      "Step: 50, x: 0.007555591873824596, loss: 8.9561\n"
     ]
    }
   ],
   "source": [
    "x = Parameter(data=torch.tensor([0.0]), requires_grad=True)\n",
    "optimizer = AdaDelta(lr=100, params=[x], alpha=0.001)\n",
    "\n",
    "loss_threshold = 1e-3\n",
    "prev_loss = 0\n",
    "\n",
    "for step in range(50):\n",
    "    loss = loss_fn(x)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Step: {step+1}, x: {x.item()}, loss: {loss.item():.4f}\")\n",
    "\n",
    "    # if abs(prev_loss - loss.item()) < loss_threshold:\n",
    "    #     print(f\"difference in loss is less than the threshold; stopping\")\n",
    "    #     break\n",
    "    # prev_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5568d2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, x: 0.10000000149011612, loss: 9.0000\n",
      "Step: 2, x: 0.19989731907844543, loss: 8.4100\n",
      "Step: 3, x: 0.29961851239204407, loss: 7.8406\n",
      "Step: 4, x: 0.39908650517463684, loss: 7.2921\n",
      "Step: 5, x: 0.4982205927371979, loss: 6.7648\n",
      "Step: 6, x: 0.5969364643096924, loss: 6.2589\n",
      "Step: 7, x: 0.6951462626457214, loss: 5.7747\n",
      "Step: 8, x: 0.7927588820457458, loss: 5.3124\n",
      "Step: 9, x: 0.8896798491477966, loss: 4.8719\n",
      "Step: 10, x: 0.9858116507530212, loss: 4.4535\n",
      "Step: 11, x: 1.0810539722442627, loss: 4.0570\n",
      "Step: 12, x: 1.1753039360046387, loss: 3.6824\n",
      "Step: 13, x: 1.268456220626831, loss: 3.3295\n",
      "Step: 14, x: 1.3604036569595337, loss: 2.9982\n",
      "Step: 15, x: 1.4510374069213867, loss: 2.6883\n",
      "Step: 16, x: 1.5402475595474243, loss: 2.3993\n",
      "Step: 17, x: 1.6279233694076538, loss: 2.1309\n",
      "Step: 18, x: 1.7139540910720825, loss: 1.8826\n",
      "Step: 19, x: 1.7982292175292969, loss: 1.6539\n",
      "Step: 20, x: 1.8806394338607788, loss: 1.4443\n",
      "Step: 21, x: 1.9610768556594849, loss: 1.2530\n",
      "Step: 22, x: 2.039436101913452, loss: 1.0794\n",
      "Step: 23, x: 2.115615129470825, loss: 0.9227\n",
      "Step: 24, x: 2.1895151138305664, loss: 0.7821\n",
      "Step: 25, x: 2.261042356491089, loss: 0.6569\n",
      "Step: 26, x: 2.330108642578125, loss: 0.5461\n",
      "Step: 27, x: 2.3966312408447266, loss: 0.4488\n",
      "Step: 28, x: 2.4605350494384766, loss: 0.3641\n",
      "Step: 29, x: 2.521752119064331, loss: 0.2910\n",
      "Step: 30, x: 2.5802228450775146, loss: 0.2287\n",
      "Step: 31, x: 2.6358964443206787, loss: 0.1762\n",
      "Step: 32, x: 2.6887319087982178, loss: 0.1326\n",
      "Step: 33, x: 2.7386980056762695, loss: 0.0969\n",
      "Step: 34, x: 2.785773754119873, loss: 0.0683\n",
      "Step: 35, x: 2.829948663711548, loss: 0.0459\n",
      "Step: 36, x: 2.871223211288452, loss: 0.0289\n",
      "Step: 37, x: 2.9096083641052246, loss: 0.0166\n",
      "Step: 38, x: 2.9451260566711426, loss: 0.0082\n",
      "Step: 39, x: 2.977808952331543, loss: 0.0030\n",
      "Step: 40, x: 3.007699728012085, loss: 0.0005\n",
      "Step: 41, x: 3.034851312637329, loss: 0.0001\n",
      "difference in loss is less than the threshold; stopping\n"
     ]
    }
   ],
   "source": [
    "x = Parameter(data=torch.tensor([0.0]), requires_grad=True)\n",
    "optimizer = Adam(lr=0.1, params=[x])\n",
    "\n",
    "loss_threshold = 1e-3\n",
    "prev_loss = 0\n",
    "\n",
    "for step in range(50):\n",
    "    loss = loss_fn(x)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Step: {step+1}, x: {x.item()}, loss: {loss.item():.4f}\")\n",
    "\n",
    "    if abs(prev_loss - loss.item()) < loss_threshold:\n",
    "        print(f\"difference in loss is less than the threshold; stopping\")\n",
    "        break\n",
    "    prev_loss = loss.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
